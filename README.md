# Credit Risk Analysis

## Overview of the analysis: Explain the purpose of this analysis.

We received data from the credit card credit dataset from LendingClub, a peer-to-peer lending services company. The objective of this analysis was to use different techniques to build and evaluate machine learning models to predict the credit risk, which is a growing problem and often hard to evaluate and specifically classify. 

## Results:

1. The over sampling model provides the highest balanced accuracy score of 63.68%. This means that 63.68% of the predictions of credit risk were actually true according to this model. The lowest accuracy score was of the balanced random forest classifier alogrithm at 48%. Therefore, if we were choosing the best model solely based on accuracy score, the random over sampling method wins. 

2. The smote oversampling method had an accuracy score of 63.84%, an average precision score of 0.99 and an average recall score of 0.62. The higher the precision score, the better. So a 0.99 precision score shows that 99% of the classified credit risks are actually accurate or that the predicitons are 99% reliable and can be trusted. Th sensitivty or recall figure is 62%. That means that among people who are actually high or low risk, 62% will be classified or identified correctly. 

3. The undersampling method had an accuracy score of 51.62%, an average precision score of 0.99 and an average recall score of 0.40. The higher the precision score, the better. So a 0.99 precision score shows that 99% of the classified credit risks are actually accurate or that the predicitons are 99% reliable and can be trusted. Th sensitivty or recall figure is 0.4. That means that among people who are actually high or low risk, 40% will be classified or identified correctly. 

4. The combination over and under sampling method had an accuracy score of 63.84%, an average precision score of 0.99 and an average recall score of 0.58. The higher the precision score, the better. So a 0.99 precision score shows that 99% of the classified credit risks are actually accurate or that the predicitons are 99% reliable and can be trusted. Th sensitivty or recall figure is 0.58. That means that among people who are actually high or low risk, 58% will be classified or identified correctly. 

5. The balanced random forest classifier model had an accuracy score of 48.4%, an average precision score of 0.48 and an average recall score of 0.48. The higher the precision score, the better. So a 48% precision score shows that 48%% of the classified credit risks are actually accurate or that the predicitons are 48% reliable and can be trusted. Th sensitivty or recall figure is also 48%. That means that among people who are actually high or low risk, 48% will be classified or identified correctly. This is clearly not a good model compared to others for credit risk. 

6. The easy ensemble AdaBoost Classifier machine learning model an accuracy score of 50%, an average precision score of 0.50 and an average recall score of 0.50. The higher the precision score, the better. So a 0.5 precision score shows that 50% of the classified credit risks are actually accurate or that the predicitons are 50% reliable and can be trusted. Th sensitivty or recall figure is 0.50. That means that among people who are actually high or low risk, 50% will be classified or identified correctly. 

## Summary

The SMOTE oversampling machine learning model is the winner here to analyze and predict the credit risk of individuals. Even though the balanced accuracy score is only 63.84%, it is the highest compared to the other models utilized. The sensitivity for all models is quite low but SMOTE has the highest at 62%. The precision score is the same for all models at 0.99 or 99%. The following explains how the numbers work: I know that I got classified as high risk, it is 99% likely that I'm actually high risk? I know that I'm actually low risk, there is a 62% chance that I will be identified as low-risk by the model? In this scenario, sensitivity is more important because from the perspective of both individual and bank, it is more important that people who are low or high risk are classified as such correctly. Because paying more weight to precision would create inefficiencies and risks for both bank and the individuals. For example, if someone is low risk, banks need to pay more attention to classifying him correctly as the cost to the bank could be significant in terms of getting the money back from the individual. All the models above have low sensitivity and so should be used carefully and not relied upon fully to make decisions. 
